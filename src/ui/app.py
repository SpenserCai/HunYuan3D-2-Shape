# -*- coding: utf-8 -*-
"""
Gradio åº”ç”¨ä¸»å…¥å£
"""

import os
import sys
import tempfile
import base64
import time
import subprocess
import atexit
from typing import Optional, Dict, Any, Tuple

import gradio as gr
from PIL import Image

from .api_client import ShapeAPIClient
from .components.image_input import create_single_image_input, create_multi_view_input
from .components.settings_panel import create_settings_panel, SUPPORTED_FORMATS
from .components.status_panel import (
    create_status_panel,
    create_status_html,
    format_health_info
)


# è‡ªå®šä¹‰ CSS - å…¨å±å®½æ•å¸ƒå±€
CUSTOM_CSS = """
/* å…¨å±å®½åº¦ */
.gradio-container {
    max-width: 100% !important;
    padding: 20px 50px !important;
}

/* ä¸»å¸ƒå±€è¡Œ - æ›´å¤§é—´è· */
.main-row {
    display: flex !important;
    flex-direction: row !important;
    flex-wrap: nowrap !important;
    gap: 40px !important;
    padding: 20px 0 !important;
    align-items: flex-start !important;
}

/* å·¦ä¾§åˆ— - å›ºå®šå®½åº¦ */
.left-column {
    flex: 0 0 420px !important;
    min-width: 400px !important;
    max-width: 450px !important;
}

/* å³ä¾§åˆ— - è‡ªé€‚åº”å¡«å…… */
.right-column {
    flex: 1 1 auto !important;
    min-width: 700px !important;
}

/* å¤šè§†å›¾å›¾åƒæ ·å¼ */
.mv-image button .wrap {
    font-size: 10px;
}
.mv-image .icon-wrap {
    width: 20px;
}

/* 3D é¢„è§ˆåŒºåŸŸ */
.model-preview {
    min-height: 600px !important;
}

/* ç”ŸæˆæŒ‰é’® */
.generate-btn {
    margin: 20px 0 !important;
    padding: 14px 24px !important;
    font-size: 17px !important;
    font-weight: 600 !important;
}
"""

# æ ‡é¢˜ HTML - æ›´ç¾è§‚
TITLE_HTML = """
<div style="text-align: center; padding: 25px 0; margin-bottom: 15px;">
    <h1 style="font-size: 2.2em; font-weight: bold; margin: 0 0 10px 0; color: #fff;">
        ğŸ¨ Hunyuan3D Shape Generation
    </h1>
    <p style="color: #9ca3af; margin: 0; font-size: 1.05em;">
        é«˜è´¨é‡å›¾åƒè½¬ 3D æ¨¡å‹ç”ŸæˆæœåŠ¡ | æ”¯æŒå•å›¾å’Œå¤šè§†å›¾è¾“å…¥
    </p>
</div>
"""


class GradioApp:
    """Gradio åº”ç”¨ç±»"""
    
    def __init__(
        self,
        api_url: str = "http://localhost:8000",
        start_backend: bool = False,
        weights_dir: str = "weights"
    ):
        self.api_url = api_url
        self.start_backend = start_backend
        self.weights_dir = weights_dir
        self.client = ShapeAPIClient(api_url)
        self.backend_process = None
        self.temp_dir = tempfile.mkdtemp(prefix="hunyuan3d_ui_")
        
    def _start_backend_server(self):
        """å¯åŠ¨åç«¯ API æœåŠ¡å™¨"""
        if not self.start_backend:
            return
            
        print("æ­£åœ¨å¯åŠ¨åç«¯ API æœåŠ¡å™¨...")
        
        from urllib.parse import urlparse
        parsed = urlparse(self.api_url)
        port = parsed.port or 8000
        
        cmd = [
            sys.executable, "-m", "uvicorn",
            "src.api.server:app",
            "--host", "0.0.0.0",
            "--port", str(port)
        ]
        
        self.backend_process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        atexit.register(self._stop_backend_server)
        
        max_retries = 60
        for i in range(max_retries):
            time.sleep(1)
            response = self.client.health_check()
            if response.success:
                print("åç«¯æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ!")
                return
            print(f"ç­‰å¾…åç«¯æœåŠ¡å™¨å¯åŠ¨... ({i+1}/{max_retries})")
        
        print("è­¦å‘Š: åç«¯æœåŠ¡å™¨å¯èƒ½æœªå®Œå…¨å¯åŠ¨")
    
    def _stop_backend_server(self):
        """åœæ­¢åç«¯æœåŠ¡å™¨"""
        if self.backend_process:
            self.backend_process.terminate()
            self.backend_process.wait()
            print("åç«¯æœåŠ¡å™¨å·²åœæ­¢")
    
    def check_health(self) -> Tuple[str, Dict]:
        """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
        response = self.client.health_check()
        
        if response.success:
            data = response.data
            status = data.get("status", "unknown")
            is_ready = data.get("is_ready", False)
            loaded_models = data.get("loaded_models", [])
            
            # åªè¦æœåŠ¡è¿é€šå°±æ˜¾ç¤ºå·²è¿æ¥
            if is_ready and loaded_models:
                status_html = create_status_html(f"æœåŠ¡å°±ç»ª ({len(loaded_models)} æ¨¡å‹å·²åŠ è½½)", "connected")
            elif status in ["healthy", "not_ready"]:
                # æœåŠ¡å·²è¿æ¥ï¼Œæ¨¡å‹ä¼šåœ¨é¦–æ¬¡è¯·æ±‚æ—¶åŠ è½½
                status_html = create_status_html("æœåŠ¡å·²è¿æ¥", "connected")
            else:
                status_html = create_status_html("æœåŠ¡çŠ¶æ€æœªçŸ¥", "disconnected")
            
            return status_html, format_health_info(data)
        else:
            return create_status_html("è¿æ¥å¤±è´¥", "error"), {"é”™è¯¯": response.error}
    
    def build_interface(self) -> gr.Blocks:
        """æ„å»º Gradio ç•Œé¢ - å·¦å³å¸ƒå±€"""
        
        # Gradio 6.0+: theme å’Œ css éœ€è¦åœ¨ launch() ä¸­ä¼ é€’
        with gr.Blocks(
            title="Hunyuan3D Shape Generation",
            fill_width=True  # ä½¿ç”¨å…¨å±å®½åº¦
        ) as demo:
            # æ ‡é¢˜ - è·¨è¶Šæ•´ä¸ªå®½åº¦
            gr.HTML(TITLE_HTML)
            
            # ä¸»è¦å†…å®¹åŒºåŸŸ - å·¦å³å¸ƒå±€
            with gr.Row(equal_height=False, elem_classes=["main-row"]):
                # ========== å·¦ä¾§é¢æ¿ - è¾“å…¥å’Œè®¾ç½® ==========
                with gr.Column(scale=2, min_width=400, elem_classes=["left-column"]):
                    # çŠ¶æ€é¢æ¿
                    status_components = create_status_panel()
                    
                    # è¾“å…¥æ¨¡å¼é€‰æ‹©
                    with gr.Tabs(selected='tab_single') as input_tabs:
                        with gr.Tab('å•å›¾æ¨¡å¼', id='tab_single'):
                            single_image = create_single_image_input()
                        
                        with gr.Tab('å¤šè§†å›¾æ¨¡å¼', id='tab_multi_view'):
                            mv_images = create_multi_view_input()
                    
                    # ç”ŸæˆæŒ‰é’®
                    generate_btn = gr.Button(
                        "ğŸš€ ç”Ÿæˆ 3D æ¨¡å‹",
                        variant="primary",
                        elem_classes=["generate-btn"],
                        size="lg"
                    )
                    
                    # è®¾ç½®é¢æ¿
                    settings = create_settings_panel()
                
                # ========== å³ä¾§é¢æ¿ - é¢„è§ˆå’Œç»“æœ ==========
                with gr.Column(scale=5, min_width=700, elem_classes=["right-column"]):
                    with gr.Tabs(selected='preview_tab') as output_tabs:
                        with gr.Tab('3D é¢„è§ˆ', id='preview_tab'):
                            model_3d = gr.Model3D(
                                label="3D æ¨¡å‹é¢„è§ˆ",
                                height=620,
                                clear_color=[0.1, 0.1, 0.15, 1.0],
                                elem_classes=["model-preview"]
                            )
                            status_text = gr.Markdown(
                                value="*ä¸Šä¼ å›¾åƒå¹¶ç‚¹å‡»ç”ŸæˆæŒ‰é’®å¼€å§‹åˆ›å»º 3D æ¨¡å‹*"
                            )
                        
                        with gr.Tab('ç”Ÿæˆç»Ÿè®¡', id='stats_tab'):
                            stats_output = gr.JSON(
                                label="ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯",
                                value={}
                            )
                    
                    # ä¸‹è½½åŒºåŸŸ
                    download_file = gr.File(
                        label="ä¸‹è½½æ¨¡å‹æ–‡ä»¶",
                        visible=True,
                        interactive=False
                    )
            
            # ========== äº‹ä»¶ç»‘å®š ==========
            
            # åˆ·æ–°çŠ¶æ€
            status_components['refresh_btn'].click(
                fn=self.check_health,
                outputs=[
                    status_components['status_indicator'],
                    status_components['health_info']
                ]
            )
            
            # é¡µé¢åŠ è½½æ—¶æ£€æŸ¥çŠ¶æ€
            demo.load(
                fn=self.check_health,
                outputs=[
                    status_components['status_indicator'],
                    status_components['health_info']
                ]
            )
            
            # ç”Ÿæˆå‡½æ•°
            def do_generate(
                single_img, 
                mv_front, mv_back, mv_left, mv_right,
                steps, guidance, octree_res, remove_bg, optimize, max_f, out_fmt,
                progress=gr.Progress()
            ):
                """æ ¹æ®è¾“å…¥åˆ¤æ–­ä½¿ç”¨å•å›¾è¿˜æ˜¯å¤šè§†å›¾ç”Ÿæˆ"""
                # åªæ£€æŸ¥æœåŠ¡æ˜¯å¦è¿é€šï¼ˆæ¨¡å‹ä¼šåœ¨ç¬¬ä¸€æ¬¡è¯·æ±‚æ—¶æ‡’åŠ è½½ï¼‰
                health_response = self.client.health_check()
                if not health_response.success:
                    return None, None, f"âŒ *æœåŠ¡æœªè¿æ¥: {health_response.error}*", {"é”™è¯¯": health_response.error}
                
                # åˆ¤æ–­ä½¿ç”¨å•å›¾è¿˜æ˜¯å¤šè§†å›¾
                if mv_front is not None or mv_back is not None or mv_left is not None or mv_right is not None:
                    return self._generate_multi_view(
                        mv_front, mv_back, mv_left, mv_right,
                        steps, guidance, octree_res, remove_bg, optimize, max_f, out_fmt,
                        progress
                    )
                return self._generate_single(
                    single_img,
                    steps, guidance, octree_res, remove_bg, optimize, max_f, out_fmt,
                    progress
                )
            
            # ç”ŸæˆæŒ‰é’®äº‹ä»¶
            generate_btn.click(
                fn=lambda: (None, None, "â³ *æ­£åœ¨ç”Ÿæˆ 3D æ¨¡å‹ï¼Œè¯·ç¨å€™...*", {}),
                outputs=[model_3d, download_file, status_text, stats_output]
            ).then(
                fn=do_generate,
                inputs=[
                    single_image,
                    mv_images['front'],
                    mv_images['back'],
                    mv_images['left'],
                    mv_images['right'],
                    settings['num_inference_steps'],
                    settings['guidance_scale'],
                    settings['octree_resolution'],
                    settings['remove_background'],
                    settings['optimize_mesh'],
                    settings['max_faces'],
                    settings['output_format']
                ],
                outputs=[model_3d, download_file, status_text, stats_output]
            )
        
        return demo
    
    def _generate_single(
        self,
        image: Optional[Image.Image],
        num_inference_steps: int,
        guidance_scale: float,
        octree_resolution: int,
        remove_background: bool,
        optimize_mesh: bool,
        max_faces: int,
        output_format: str,
        progress=gr.Progress()
    ) -> Tuple[Optional[str], Optional[str], str, Dict]:
        """å•å›¾ç”Ÿæˆ"""
        if image is None:
            return None, None, "âŒ *è¯·ä¸Šä¼ å›¾åƒ*", {"é”™è¯¯": "è¯·ä¸Šä¼ å›¾åƒ"}
        
        try:
            progress(0.1, desc="æ­£åœ¨ä¸Šä¼ å›¾åƒ...")
            
            response = self.client.generate_single(
                image=image,
                num_inference_steps=int(num_inference_steps),
                guidance_scale=float(guidance_scale),
                octree_resolution=int(octree_resolution),
                remove_background=remove_background,
                optimize_mesh=optimize_mesh,
                max_faces=int(max_faces),
                output_format=output_format
            )
            
            if not response.success:
                return None, None, f"âŒ *ç”Ÿæˆå¤±è´¥: {response.error}*", {"é”™è¯¯": response.error}
            
            progress(0.7, desc="æ­£åœ¨è·å–ç»“æœ...")
            
            task_id = response.data.get("task_id")
            result_response = self.client.get_task_result(task_id)
            
            if not result_response.success:
                return None, None, f"âŒ *è·å–ç»“æœå¤±è´¥: {result_response.error}*", {"é”™è¯¯": result_response.error}
            
            progress(0.9, desc="æ­£åœ¨å¤„ç†æ¨¡å‹...")
            
            result_data = result_response.data
            mesh_bytes = base64.b64decode(result_data["mesh_base64"])
            output_path = os.path.join(self.temp_dir, f"{task_id}.{output_format}")
            
            with open(output_path, "wb") as f:
                f.write(mesh_bytes)
            
            stats = {
                "ä»»åŠ¡ ID": task_id,
                "å¤„ç†æ—¶é—´": f"{result_data.get('processing_time', 0):.2f} ç§’",
                "è¾“å…¥æ¨¡å¼": result_data.get("input_mode", "single"),
                "è¾“å‡ºæ ¼å¼": result_data.get("format", output_format)
            }
            
            progress(1.0, desc="å®Œæˆ!")
            return output_path, output_path, "âœ… *ç”Ÿæˆå®Œæˆï¼å¯ä»¥åœ¨ä¸Šæ–¹é¢„è§ˆå’Œä¸‹è½½æ¨¡å‹*", stats
            
        except Exception as e:
            return None, None, f"âŒ *å‘ç”Ÿé”™è¯¯: {str(e)}*", {"é”™è¯¯": str(e)}
    
    def _generate_multi_view(
        self,
        front_image: Optional[Image.Image],
        back_image: Optional[Image.Image],
        left_image: Optional[Image.Image],
        right_image: Optional[Image.Image],
        num_inference_steps: int,
        guidance_scale: float,
        octree_resolution: int,
        remove_background: bool,
        optimize_mesh: bool,
        max_faces: int,
        output_format: str,
        progress=gr.Progress()
    ) -> Tuple[Optional[str], Optional[str], str, Dict]:
        """å¤šè§†å›¾ç”Ÿæˆ"""
        if front_image is None:
            return None, None, "âŒ *è¯·è‡³å°‘ä¸Šä¼ æ­£é¢è§†å›¾å›¾åƒ*", {"é”™è¯¯": "è¯·è‡³å°‘ä¸Šä¼ æ­£é¢è§†å›¾å›¾åƒ"}
        
        views = {"front": front_image}
        if back_image is not None:
            views["back"] = back_image
        if left_image is not None:
            views["left"] = left_image
        if right_image is not None:
            views["right"] = right_image
        
        try:
            progress(0.1, desc=f"æ­£åœ¨ä¸Šä¼  {len(views)} ä¸ªè§†å›¾...")
            
            response = self.client.generate_multi_view(
                views=views,
                num_inference_steps=int(num_inference_steps),
                guidance_scale=float(guidance_scale),
                octree_resolution=int(octree_resolution),
                remove_background=remove_background,
                optimize_mesh=optimize_mesh,
                max_faces=int(max_faces),
                output_format=output_format
            )
            
            if not response.success:
                return None, None, f"âŒ *ç”Ÿæˆå¤±è´¥: {response.error}*", {"é”™è¯¯": response.error}
            
            progress(0.7, desc="æ­£åœ¨è·å–ç»“æœ...")
            
            task_id = response.data.get("task_id")
            result_response = self.client.get_task_result(task_id)
            
            if not result_response.success:
                return None, None, f"âŒ *è·å–ç»“æœå¤±è´¥: {result_response.error}*", {"é”™è¯¯": result_response.error}
            
            progress(0.9, desc="æ­£åœ¨å¤„ç†æ¨¡å‹...")
            
            result_data = result_response.data
            mesh_bytes = base64.b64decode(result_data["mesh_base64"])
            output_path = os.path.join(self.temp_dir, f"{task_id}.{output_format}")
            
            with open(output_path, "wb") as f:
                f.write(mesh_bytes)
            
            stats = {
                "ä»»åŠ¡ ID": task_id,
                "å¤„ç†æ—¶é—´": f"{result_data.get('processing_time', 0):.2f} ç§’",
                "è¾“å…¥æ¨¡å¼": "multi_view",
                "è§†å›¾æ•°é‡": result_data.get("view_count", len(views)),
                "è¾“å‡ºæ ¼å¼": result_data.get("format", output_format)
            }
            
            progress(1.0, desc="å®Œæˆ!")
            return output_path, output_path, "âœ… *ç”Ÿæˆå®Œæˆï¼å¯ä»¥åœ¨ä¸Šæ–¹é¢„è§ˆå’Œä¸‹è½½æ¨¡å‹*", stats
            
        except Exception as e:
            return None, None, f"âŒ *å‘ç”Ÿé”™è¯¯: {str(e)}*", {"é”™è¯¯": str(e)}


def create_app(
    api_url: str = "http://localhost:8000",
    start_backend: bool = False,
    weights_dir: str = "weights"
) -> gr.Blocks:
    """åˆ›å»º Gradio åº”ç”¨"""
    app = GradioApp(
        api_url=api_url,
        start_backend=start_backend,
        weights_dir=weights_dir
    )
    
    if start_backend:
        app._start_backend_server()
    
    return app.build_interface()


def launch_app(
    api_url: str = "http://localhost:8000",
    start_backend: bool = False,
    weights_dir: str = "weights",
    host: str = "0.0.0.0",
    port: int = 7860,
    share: bool = False
):
    """å¯åŠ¨ Gradio åº”ç”¨"""
    demo = create_app(
        api_url=api_url,
        start_backend=start_backend,
        weights_dir=weights_dir
    )
    
    # Gradio 6.0+: theme å’Œ css åœ¨ launch() ä¸­ä¼ é€’
    demo.launch(
        server_name=host,
        server_port=port,
        share=share,
        show_error=True,
        theme=gr.themes.Base(),
        css=CUSTOM_CSS
    )
