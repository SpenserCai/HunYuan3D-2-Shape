# -*- coding: utf-8 -*-
"""
Gradio åº”ç”¨ä¸»å…¥å£
"""

import os
import sys
import tempfile
import base64
import time
import threading
import subprocess
import atexit
from typing import Optional, Dict, Any, Tuple
from pathlib import Path

import gradio as gr
from PIL import Image

from .api_client import ShapeAPIClient
from .styles import CUSTOM_CSS, TITLE_HTML, FOOTER_HTML
from .components.image_input import create_single_image_input, create_multi_view_input
from .components.settings_panel import create_settings_panel, SUPPORTED_FORMATS
from .components.model_viewer import (
    create_model_viewer,
    MODEL_VIEWER_PLACEHOLDER,
    create_model_viewer_html,
    create_processing_html,
    create_error_html
)
from .components.status_panel import (
    create_status_panel,
    create_status_html,
    format_health_info
)


class GradioApp:
    """Gradio åº”ç”¨ç±»"""
    
    def __init__(
        self,
        api_url: str = "http://localhost:8000",
        start_backend: bool = False,
        weights_dir: str = "weights"
    ):
        """
        åˆå§‹åŒ–åº”ç”¨
        
        Args:
            api_url: API æœåŠ¡å™¨åœ°å€
            start_backend: æ˜¯å¦å¯åŠ¨åç«¯æœåŠ¡
            weights_dir: æ¨¡å‹æƒé‡ç›®å½•
        """
        self.api_url = api_url
        self.start_backend = start_backend
        self.weights_dir = weights_dir
        self.client = ShapeAPIClient(api_url)
        self.backend_process = None
        self.temp_dir = tempfile.mkdtemp(prefix="hunyuan3d_ui_")
        
    def _start_backend_server(self):
        """å¯åŠ¨åç«¯ API æœåŠ¡å™¨"""
        if not self.start_backend:
            return
            
        print("æ­£åœ¨å¯åŠ¨åç«¯ API æœåŠ¡å™¨...")
        
        # è§£æ API URL è·å–ç«¯å£
        from urllib.parse import urlparse
        parsed = urlparse(self.api_url)
        port = parsed.port or 8000
        
        # ä½¿ç”¨ uvicorn å¯åŠ¨ FastAPI
        cmd = [
            sys.executable, "-m", "uvicorn",
            "src.api.server:app",
            "--host", "0.0.0.0",
            "--port", str(port)
        ]
        
        self.backend_process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        # æ³¨å†Œé€€å‡ºæ—¶æ¸…ç†
        atexit.register(self._stop_backend_server)
        
        # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
        max_retries = 60
        for i in range(max_retries):
            time.sleep(1)
            response = self.client.health_check()
            if response.success:
                print("åç«¯æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ!")
                return
            print(f"ç­‰å¾…åç«¯æœåŠ¡å™¨å¯åŠ¨... ({i+1}/{max_retries})")
        
        print("è­¦å‘Š: åç«¯æœåŠ¡å™¨å¯èƒ½æœªå®Œå…¨å¯åŠ¨")
    
    def _stop_backend_server(self):
        """åœæ­¢åç«¯æœåŠ¡å™¨"""
        if self.backend_process:
            self.backend_process.terminate()
            self.backend_process.wait()
            print("åç«¯æœåŠ¡å™¨å·²åœæ­¢")
    
    def check_health(self) -> Tuple[str, Dict]:
        """
        æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
        
        Returns:
            (çŠ¶æ€ HTML, å¥åº·ä¿¡æ¯å­—å…¸)
        """
        response = self.client.health_check()
        
        if response.success:
            data = response.data
            is_ready = data.get("is_ready", False)
            
            if is_ready:
                status_html = create_status_html("æœåŠ¡å°±ç»ª", "connected")
            else:
                status_html = create_status_html("æœåŠ¡æœªå°±ç»ª", "disconnected")
            
            return status_html, format_health_info(data)
        else:
            return create_status_html("è¿æ¥å¤±è´¥", "error"), {"é”™è¯¯": response.error}
    
    def build_interface(self) -> gr.Blocks:
        """
        æ„å»º Gradio ç•Œé¢
        
        Returns:
            Gradio Blocks åº”ç”¨
        """
        with gr.Blocks(
            title="Hunyuan3D Shape Generation",
            theme=gr.themes.Soft(
                primary_hue="indigo",
                secondary_hue="purple"
            ),
            css=CUSTOM_CSS
        ) as demo:
            # æ ‡é¢˜
            gr.HTML(TITLE_HTML)
            
            with gr.Row():
                # å·¦ä¾§é¢æ¿ - è¾“å…¥å’Œè®¾ç½®
                with gr.Column(scale=4):
                    # çŠ¶æ€é¢æ¿
                    status_components = create_status_panel()
                    
                    # è¾“å…¥æ¨¡å¼é€‰æ‹©
                    with gr.Tabs() as input_tabs:
                        # å•å›¾æ¨¡å¼
                        with gr.Tab("å•å›¾æ¨¡å¼", id="single_mode"):
                            single_image = create_single_image_input()
                            single_generate_btn = gr.Button(
                                "ğŸš€ ç”Ÿæˆ 3D æ¨¡å‹",
                                variant="primary",
                                elem_classes=["generate-btn"]
                            )
                        
                        # å¤šè§†å›¾æ¨¡å¼
                        with gr.Tab("å¤šè§†å›¾æ¨¡å¼", id="multi_view_mode"):
                            mv_images = create_multi_view_input()
                            mv_generate_btn = gr.Button(
                                "ğŸš€ ç”Ÿæˆ 3D æ¨¡å‹ (å¤šè§†å›¾)",
                                variant="primary",
                                elem_classes=["generate-btn"]
                            )
                    
                    # è®¾ç½®é¢æ¿
                    settings = create_settings_panel()
                
                # å³ä¾§é¢æ¿ - é¢„è§ˆå’Œç»“æœ
                with gr.Column(scale=6):
                    with gr.Tabs() as output_tabs:
                        with gr.Tab("3D é¢„è§ˆ", id="preview_tab"):
                            # ä½¿ç”¨ Gradio å†…ç½®çš„ Model3D ç»„ä»¶
                            model_3d = gr.Model3D(
                                label="3D æ¨¡å‹é¢„è§ˆ",
                                height=500,
                                clear_color=[0.1, 0.1, 0.15, 1.0],
                                elem_classes=["model-viewer-container"]
                            )
                            
                            # çŠ¶æ€æç¤º
                            status_text = gr.Markdown(
                                value="*ä¸Šä¼ å›¾åƒå¹¶ç‚¹å‡»ç”ŸæˆæŒ‰é’®å¼€å§‹åˆ›å»º 3D æ¨¡å‹*",
                                elem_classes=["status-text"]
                            )
                            
                            with gr.Row():
                                download_file = gr.File(
                                    label="ä¸‹è½½æ¨¡å‹æ–‡ä»¶",
                                    visible=True,
                                    interactive=False
                                )
                        
                        with gr.Tab("ç”Ÿæˆç»Ÿè®¡", id="stats_tab"):
                            stats_output = gr.JSON(
                                label="ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯",
                                value={}
                            )
            
            # é¡µè„š
            gr.HTML(FOOTER_HTML)
            
            # äº‹ä»¶ç»‘å®š
            
            # åˆ·æ–°çŠ¶æ€
            status_components['refresh_btn'].click(
                fn=self.check_health,
                outputs=[
                    status_components['status_indicator'],
                    status_components['health_info']
                ]
            )
            
            # é¡µé¢åŠ è½½æ—¶æ£€æŸ¥çŠ¶æ€
            demo.load(
                fn=self.check_health,
                outputs=[
                    status_components['status_indicator'],
                    status_components['health_info']
                ]
            )
            
            # å•å›¾ç”Ÿæˆ
            single_generate_btn.click(
                fn=lambda: (None, None, "â³ *æ­£åœ¨ç”Ÿæˆ 3D æ¨¡å‹ï¼Œè¯·ç¨å€™...*", {}),
                outputs=[model_3d, download_file, status_text, stats_output]
            ).then(
                fn=self._generate_single_wrapper,
                inputs=[
                    single_image,
                    settings['num_inference_steps'],
                    settings['guidance_scale'],
                    settings['octree_resolution'],
                    settings['remove_background'],
                    settings['optimize_mesh'],
                    settings['max_faces'],
                    settings['output_format']
                ],
                outputs=[model_3d, download_file, status_text, stats_output]
            )
            
            # å¤šè§†å›¾ç”Ÿæˆ
            mv_generate_btn.click(
                fn=lambda: (None, None, "â³ *æ­£åœ¨ç”Ÿæˆ 3D æ¨¡å‹ (å¤šè§†å›¾)ï¼Œè¯·ç¨å€™...*", {}),
                outputs=[model_3d, download_file, status_text, stats_output]
            ).then(
                fn=self._generate_multi_view_wrapper,
                inputs=[
                    mv_images['front'],
                    mv_images['back'],
                    mv_images['left'],
                    mv_images['right'],
                    settings['num_inference_steps'],
                    settings['guidance_scale'],
                    settings['octree_resolution'],
                    settings['remove_background'],
                    settings['optimize_mesh'],
                    settings['max_faces'],
                    settings['output_format']
                ],
                outputs=[model_3d, download_file, status_text, stats_output]
            )
        
        return demo
    
    def _generate_single_wrapper(
        self,
        image: Optional[Image.Image],
        num_inference_steps: int,
        guidance_scale: float,
        octree_resolution: int,
        remove_background: bool,
        optimize_mesh: bool,
        max_faces: int,
        output_format: str,
        progress=gr.Progress()
    ) -> Tuple[Optional[str], Optional[str], str, Dict]:
        """å•å›¾ç”ŸæˆåŒ…è£…å™¨ï¼Œè¿”å›é€‚åˆ Model3D ç»„ä»¶çš„æ ¼å¼"""
        if image is None:
            return None, None, "âŒ *è¯·ä¸Šä¼ å›¾åƒ*", {"é”™è¯¯": "è¯·ä¸Šä¼ å›¾åƒ"}
        
        try:
            progress(0.1, desc="æ­£åœ¨ä¸Šä¼ å›¾åƒ...")
            
            response = self.client.generate_single(
                image=image,
                num_inference_steps=int(num_inference_steps),
                guidance_scale=float(guidance_scale),
                octree_resolution=int(octree_resolution),
                remove_background=remove_background,
                optimize_mesh=optimize_mesh,
                max_faces=int(max_faces),
                output_format=output_format
            )
            
            if not response.success:
                return None, None, f"âŒ *ç”Ÿæˆå¤±è´¥: {response.error}*", {"é”™è¯¯": response.error}
            
            progress(0.7, desc="æ­£åœ¨è·å–ç»“æœ...")
            
            task_id = response.data.get("task_id")
            result_response = self.client.get_task_result(task_id)
            
            if not result_response.success:
                return None, None, f"âŒ *è·å–ç»“æœå¤±è´¥: {result_response.error}*", {"é”™è¯¯": result_response.error}
            
            progress(0.9, desc="æ­£åœ¨å¤„ç†æ¨¡å‹...")
            
            result_data = result_response.data
            mesh_bytes = base64.b64decode(result_data["mesh_base64"])
            output_path = os.path.join(self.temp_dir, f"{task_id}.{output_format}")
            
            with open(output_path, "wb") as f:
                f.write(mesh_bytes)
            
            stats = {
                "ä»»åŠ¡ ID": task_id,
                "å¤„ç†æ—¶é—´": f"{result_data.get('processing_time', 0):.2f} ç§’",
                "è¾“å…¥æ¨¡å¼": result_data.get("input_mode", "single"),
                "è¾“å‡ºæ ¼å¼": result_data.get("format", output_format)
            }
            
            progress(1.0, desc="å®Œæˆ!")
            
            return output_path, output_path, "âœ… *ç”Ÿæˆå®Œæˆï¼å¯ä»¥åœ¨ä¸Šæ–¹é¢„è§ˆå’Œä¸‹è½½æ¨¡å‹*", stats
            
        except Exception as e:
            return None, None, f"âŒ *å‘ç”Ÿé”™è¯¯: {str(e)}*", {"é”™è¯¯": str(e)}
    
    def _generate_multi_view_wrapper(
        self,
        front_image: Optional[Image.Image],
        back_image: Optional[Image.Image],
        left_image: Optional[Image.Image],
        right_image: Optional[Image.Image],
        num_inference_steps: int,
        guidance_scale: float,
        octree_resolution: int,
        remove_background: bool,
        optimize_mesh: bool,
        max_faces: int,
        output_format: str,
        progress=gr.Progress()
    ) -> Tuple[Optional[str], Optional[str], str, Dict]:
        """å¤šè§†å›¾ç”ŸæˆåŒ…è£…å™¨ï¼Œè¿”å›é€‚åˆ Model3D ç»„ä»¶çš„æ ¼å¼"""
        if front_image is None:
            return None, None, "âŒ *è¯·è‡³å°‘ä¸Šä¼ æ­£é¢è§†å›¾å›¾åƒ*", {"é”™è¯¯": "è¯·è‡³å°‘ä¸Šä¼ æ­£é¢è§†å›¾å›¾åƒ"}
        
        views = {"front": front_image}
        if back_image is not None:
            views["back"] = back_image
        if left_image is not None:
            views["left"] = left_image
        if right_image is not None:
            views["right"] = right_image
        
        try:
            progress(0.1, desc=f"æ­£åœ¨ä¸Šä¼  {len(views)} ä¸ªè§†å›¾...")
            
            response = self.client.generate_multi_view(
                views=views,
                num_inference_steps=int(num_inference_steps),
                guidance_scale=float(guidance_scale),
                octree_resolution=int(octree_resolution),
                remove_background=remove_background,
                optimize_mesh=optimize_mesh,
                max_faces=int(max_faces),
                output_format=output_format
            )
            
            if not response.success:
                return None, None, f"âŒ *ç”Ÿæˆå¤±è´¥: {response.error}*", {"é”™è¯¯": response.error}
            
            progress(0.7, desc="æ­£åœ¨è·å–ç»“æœ...")
            
            task_id = response.data.get("task_id")
            result_response = self.client.get_task_result(task_id)
            
            if not result_response.success:
                return None, None, f"âŒ *è·å–ç»“æœå¤±è´¥: {result_response.error}*", {"é”™è¯¯": result_response.error}
            
            progress(0.9, desc="æ­£åœ¨å¤„ç†æ¨¡å‹...")
            
            result_data = result_response.data
            mesh_bytes = base64.b64decode(result_data["mesh_base64"])
            output_path = os.path.join(self.temp_dir, f"{task_id}.{output_format}")
            
            with open(output_path, "wb") as f:
                f.write(mesh_bytes)
            
            stats = {
                "ä»»åŠ¡ ID": task_id,
                "å¤„ç†æ—¶é—´": f"{result_data.get('processing_time', 0):.2f} ç§’",
                "è¾“å…¥æ¨¡å¼": "multi_view",
                "è§†å›¾æ•°é‡": result_data.get("view_count", len(views)),
                "è¾“å‡ºæ ¼å¼": result_data.get("format", output_format)
            }
            
            progress(1.0, desc="å®Œæˆ!")
            
            return output_path, output_path, "âœ… *ç”Ÿæˆå®Œæˆï¼å¯ä»¥åœ¨ä¸Šæ–¹é¢„è§ˆå’Œä¸‹è½½æ¨¡å‹*", stats
            
        except Exception as e:
            return None, None, f"âŒ *å‘ç”Ÿé”™è¯¯: {str(e)}*", {"é”™è¯¯": str(e)}


def create_app(
    api_url: str = "http://localhost:8000",
    start_backend: bool = False,
    weights_dir: str = "weights"
) -> gr.Blocks:
    """
    åˆ›å»º Gradio åº”ç”¨
    
    Args:
        api_url: API æœåŠ¡å™¨åœ°å€
        start_backend: æ˜¯å¦å¯åŠ¨åç«¯æœåŠ¡
        weights_dir: æ¨¡å‹æƒé‡ç›®å½•
        
    Returns:
        Gradio Blocks åº”ç”¨
    """
    app = GradioApp(
        api_url=api_url,
        start_backend=start_backend,
        weights_dir=weights_dir
    )
    
    if start_backend:
        app._start_backend_server()
    
    return app.build_interface()


def launch_app(
    api_url: str = "http://localhost:8000",
    start_backend: bool = False,
    weights_dir: str = "weights",
    host: str = "0.0.0.0",
    port: int = 7860,
    share: bool = False
):
    """
    å¯åŠ¨ Gradio åº”ç”¨
    
    Args:
        api_url: API æœåŠ¡å™¨åœ°å€
        start_backend: æ˜¯å¦å¯åŠ¨åç«¯æœåŠ¡
        weights_dir: æ¨¡å‹æƒé‡ç›®å½•
        host: ç›‘å¬åœ°å€
        port: ç›‘å¬ç«¯å£
        share: æ˜¯å¦åˆ›å»ºå…¬å…±é“¾æ¥
    """
    demo = create_app(
        api_url=api_url,
        start_backend=start_backend,
        weights_dir=weights_dir
    )
    
    demo.launch(
        server_name=host,
        server_port=port,
        share=share,
        show_error=True
    )
